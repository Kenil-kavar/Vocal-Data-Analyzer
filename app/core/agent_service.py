import os
import logging
from app.agents.agent_setup import coordinator, inspector, visualizer, reporter, llm_config_coordinator
import autogen
import glob
import shutil

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Fix: Use relative path or environment variable
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
RESULTS_DIR = os.path.join(BASE_DIR, "data", "results")

def run_eda_workflow(session_id: str, prompt: str, dataset_path: str, data_preview: str):
    session_results_dir = os.path.join(RESULTS_DIR, session_id)
    os.makedirs(session_results_dir, exist_ok=True)

    # Define the initial message for the coordinator
    initial_prompt = f"""
    User request: '{prompt}'
    Dataset path: '{dataset_path}'
    Results directory: '{session_results_dir}'

    Here is a preview of the data:
    {data_preview}

    Please start the EDA workflow based on this data.
    """

    try:
        # Create a code executor agent to actually RUN the code that agents generate
        code_executor = autogen.UserProxyAgent(
            name="CodeExecutor",
            system_message="You execute code generated by other agents. Run all Python code blocks you receive.",
            human_input_mode="NEVER",
            code_execution_config={"work_dir": "coding", "use_docker": False},
        )
        
        # Create a group chat - agents will run until max_round
        groupchat = autogen.GroupChat(
            agents=[coordinator, inspector, visualizer, reporter, code_executor],
            messages=[],
            max_round=30,  # Let it run longer to complete tasks
        )
        manager = autogen.GroupChatManager(
            groupchat=groupchat, 
            llm_config=llm_config_coordinator,
        )

        # Initiate the chat
        coordinator.initiate_chat(
            manager,
            message=initial_prompt,
        )

        # --- FILE REGISTRATION ---
        # Files are created directly in session_results_dir by the agents
        # Scan that directory and register them in the database
        
        file_patterns = {
            "cleaned_csv": "cleaned*.csv",
            "cleaned_excel": "*.xlsx",
            "cleaned_json": "cleaned*.json",
            "visualization": "*.png",
        }
        
        registered_files = []
        
        # Scan the results directory for output files
        for file_type, pattern in file_patterns.items():
            search_pattern = os.path.join(session_results_dir, pattern)
            logger.info(f"Searching for {file_type} files: {search_pattern}")
            
            for file_path in glob.glob(search_pattern):
                filename = os.path.basename(file_path)
                
                # Skip graph_data.json
                if filename == 'graph_data.json':
                    continue
                
                # Register in database
                try:
                    from app.database import database, models
                    db = next(database.get_db())
                    db_file = models.File(
                        session_id=session_id,
                        file_type=file_type,
                        file_path=file_path
                    )
                    db.add(db_file)
                    db.commit()
                    registered_files.append({"filename": filename, "type": file_type, "path": file_path})
                    logger.info(f"✅ Registered {filename} in database with type '{file_type}'")
                except Exception as e:
                    logger.error(f"❌ Failed to register {filename} in DB: {e}")
        
        # Clean up: Remove Python code files from coding directory
        for py_file in glob.glob(os.path.join("coding", "*.py")):
            try:
                os.remove(py_file)
                logger.info(f"Removed temporary code file: {os.path.basename(py_file)}")
            except Exception as e:
                logger.warning(f"Failed to remove {py_file}: {e}")
        
        logger.info(f"✅ Total files registered: {len(registered_files)}")
        # ---------------------------------

        # Extract the conversation history
        chat_history = groupchat.messages

        # Parse chat_history for likely chart/EDA results
        line_data = []
        pie_data = []
        for msg in chat_history:
            content = msg.get("content", "")
            # Look for JSON-like chart data in the message content
            if isinstance(content, str):
                if '"line"' in content or "'line'" in content:
                    try:
                        import json
                        # Try to extract JSON from the string
                        start = content.find('{')
                        end = content.rfind('}')
                        if start != -1 and end != -1:
                            chart_json = json.loads(content[start:end+1].replace("'", '"'))
                            if isinstance(chart_json, dict):
                                if "line" in chart_json and isinstance(chart_json["line"], list):
                                    line_data = chart_json["line"]
                                if "pie" in chart_json and isinstance(chart_json["pie"], list):
                                    pie_data = chart_json["pie"]
                    except Exception:
                        pass
        graph_data = {"line": line_data, "pie": pie_data}
        # Store graph data as a log in the database
        try:
            from app.database import database, models
            import json
            db = next(database.get_db())
            graph_log = models.Log(
                session_id=session_id,
                command="graph_data",
                output_summary=json.dumps(graph_data)
            )
            db.add(graph_log)
            db.commit()
        except Exception as db_exc:
            logger.error(f"Failed to store graph data in DB: {db_exc}")
        # Write graph_data as graph_data.json in results directory
        try:
            import json
            logger.info(f"Attempting to write graph_data.json to: {session_results_dir}")
            logger.info(f"graph_data content: {graph_data}")
            with open(os.path.join(session_results_dir, "graph_data.json"), "w") as f:
                json.dump(graph_data, f)
            logger.info("Successfully wrote graph_data.json.")
        except Exception as file_exc:
            logger.error(f"Failed to write graph_data.json: {file_exc}")
        return {
            "message": "EDA workflow completed.",
            "results_path": session_results_dir,
            "chat_history": chat_history,
            "graph_data": graph_data
        }

    except Exception as e:
        logger.error(f"Error in EDA workflow for session {session_id}: {str(e)}")
        raise e
